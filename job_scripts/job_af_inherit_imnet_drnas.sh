#!/bin/bash
#SBATCH -p ml_gpu-rtx2080
#SBATCH --gres=gpu:8
#SBATCH -t 6-00:00:00 # time (D-HH:MM)
#SBATCH -c 16 # number of cores
#SBATCH -o logs/%j.%x.%N.out # STDOUT  (the folder log has to be created prior to running or this won't work)
#SBATCH -e logs/%j.%x.%N.err # STDERR  (the folder log has to be created prior to running or this won't work)
#SBATCH -J small_autoformer # sets the job name. If not specified, the file name will be used as job name
#SBATCH --mail-type=END,FAIL # (recive mails about end and timeouts/crashes of your job)
python -m torch.distributed.launch --nproc_per_node=8  --master_port=1723 --use_env search_spaces/AutoFormer/supernet_train_inherit.py --gp --change_qkv --relative_position --mode super --dist-eval --cfg search_spaces/AutoFormer/experiments/supernet/supernet-T.yaml  --patch_size 16  --epochs 1500 --warmup-epochs 20 --output drnas_imnet_finetune_2/ --batch-size 64 --amp --model_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/drnas_imnet_slow_finetune/checkpoint_72.pth  --df_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/output_imagenet_drnas_we2/arch_trajectory.pkl --lr 1e-6 --warmup-lr 1e-6 --min-lr 1e-6
#python -m torch.distributed.launch --nproc_per_node=8  --master_port=1723 --use_env search_spaces/AutoFormer/supernet_train_inherit.py --gp --change_qkv --relative_position --mode super --dist-eval --cfg search_spaces/AutoFormer/experiments/supernet/supernet-T.yaml  --patch_size 16  --epochs 1500 --warmup-epochs 20 --output gdas_imnet_finetune_2/ --batch-size 64 --amp --model_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/gdas_imnet_fast_finetune/checkpoint_60.pth  --df_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/output_imagenet_gdas_we2/arch_trajectory.pkl --lr 1e-6 --warmup-lr 1e-6 --min-lr 1e-6
#python -m torch.distributed.launch --nproc_per_node=8  --master_port=1723 --use_env search_spaces/AutoFormer/supernet_train_inherit.py --gp --change_qkv --relative_position --mode super --dist-eval --cfg search_spaces/AutoFormer/experiments/supernet/supernet-T.yaml  --patch_size 16  --epochs 1500 --warmup-epochs 20 --output darts_imnet_slow_finetune_2/ --batch-size 64 --amp --model_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/darts_imnet_slow_finetune/checkpoint_73.pth  --df_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/output_imagenet_darts_we2/arch_trajectory.pkl --lr 1e-6 --warmup-lr 1e-6 --min-lr 1e-6
#python -m torch.distributed.launch --nproc_per_node=8  --master_port=1723 --use_env search_spaces/AutoFormer/supernet_train_inherit.py --gp --change_qkv --relative_position --mode super --dist-eval --cfg search_spaces/AutoFormer/experiments/supernet/supernet-T.yaml  --patch_size 16  --epochs 1500 --warmup-epochs 20 --output drnas_imnet_slow_finetune/ --batch-size 64 --amp --model_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/output_imagenet_drnas_we2/checkpoint_77.pth  --df_path /work/dlclarge2/sukthank-tanglenas/TangleNAS-dev/output_imagenet_drnas_we2/arch_trajectory.pkl --lr 1e-6 --warmup-lr 1e-5 --min-lr 1e-7
